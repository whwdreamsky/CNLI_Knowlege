Training with following options: /home/oliver/Documents/workplace/project/DAM/src/train_cnli.py --model mlp -r 0.0004 --optim adam -e 30 -b 32 --save /home/oliver/Documents/workplace/project/DAM/model_weights/cnli_mlp_trainvector/
Loading embeddings
Embeddings have shape (43578, 200)
2019-04-29 15:13:28.627472: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2019-04-29 15:13:28.627504: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2019-04-29 15:13:28.627513: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Creating model
Reading data from /home/oliver/Documents/workplace/project/data/cnli_back/blunlp/cnli_train_seg_ltp.txt
Reading data from /home/oliver/Documents/workplace/project/data/cnli_back/blunlp/cnli_dev_seg_ltp.txt
Reading data from /home/oliver/Documents/workplace/project/data/cnli_back/blunlp/cnli_dev_seg_ltp.txt
Converting words to indices
Training sentences have shape (90000, 43) (firsts) and (90000, 34) (seconds)
Validation sentences have shape (10000, 35) (firsts) and (10000, 34) (seconds)
Test sentences have shape (10000, 35) (firsts) and (10000, 34) (seconds)
projection/weights:0: 60000 params
inter-attention/layer1/dense/kernel:0: 90000 params
inter-attention/layer1/dense/bias:0: 300 params
inter-attention/layer2/dense/kernel:0: 90000 params
inter-attention/layer2/dense/bias:0: 300 params
comparison/layer1/dense/kernel:0: 360000 params
comparison/layer1/dense/bias:0: 300 params
comparison/layer2/dense/kernel:0: 90000 params
comparison/layer2/dense/bias:0: 300 params
aggregation/linear/weights:0: 900 params
aggregation/linear/bias:0: 3 params
aggregation/layer1/dense/kernel:0: 360000 params
aggregation/layer1/dense/bias:0: 300 params
aggregation/layer2/dense/kernel:0: 90000 params
aggregation/layer2/dense/bias:0: 300 params
Total parameters: 1142703
Starting training
0 completed epochs, 1000 batches	Avg train loss: 1.027942	Avg train acc: 0.4715	Validation loss: 0.896252	Validation acc: 0.5878
0 completed epochs, 2000 batches	Avg train loss: 0.889899	Avg train acc: 0.5941	Validation loss: 0.813279	Validation acc: 0.6476	(saved model)
1 completed epochs, 3000 batches	Avg train loss: 0.845222	Avg train acc: 0.6188	Validation loss: 0.782486	Validation acc: 0.6639	(saved model)
1 completed epochs, 4000 batches	Avg train loss: 0.815593	Avg train acc: 0.6387	Validation loss: 0.747454	Validation acc: 0.6853	(saved model)
1 completed epochs, 5000 batches	Avg train loss: 0.800175	Avg train acc: 0.6498	Validation loss: 0.741512	Validation acc: 0.6897	(saved model)
2 completed epochs, 6000 batches	Avg train loss: 0.771782	Avg train acc: 0.6626	Validation loss: 0.733401	Validation acc: 0.6926	(saved model)
2 completed epochs, 7000 batches	Avg train loss: 0.760012	Avg train acc: 0.6717	Validation loss: 0.722897	Validation acc: 0.6950	(saved model)
2 completed epochs, 8000 batches	Avg train loss: 0.753552	Avg train acc: 0.6760	Validation loss: 0.705617	Validation acc: 0.7055	(saved model)
3 completed epochs, 9000 batches	Avg train loss: 0.729391	Avg train acc: 0.6906	Validation loss: 0.694621	Validation acc: 0.7153	(saved model)
